200
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79], [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119], [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139], [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159], [160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]]
Creating original model: vit_base_patch16_224
[Sequential(
  (0): Linear(in_features=768, out_features=1536, bias=True)
  (1): GELU(approximate='none')
  (2): Dropout(p=0.0, inplace=False)
), Sequential(
  (0): Linear(in_features=1536, out_features=768, bias=True)
  (1): Dropout(p=0.0, inplace=False)
)]
Creating model: vit_base_patch16_224
Namespace(aa=None, angle_epsilon=0.18, batch_size=24, batchwise_prompt=False, ca_lr=0.005, ca_storage_efficient_method='multi-centroid', clip_grad=1.0, color_jitter=None, config='cub_hideprompt_5e', cooldown_epochs=10, crct_epochs=30, data_path='./datasets/', dataset='Split-CUB200', dataset_name='cub', decay_epochs=30, decay_rate=0.1, device='cuda', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, e_prompt_layer_idx=[0, 1, 2, 3, 4], embedding_key='cls', epochs=50, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], g_prompt_layer_idx=[], g_prompt_length=5, global_pool='token', head_type='token', initializer='uniform', input_size=224, larger_prompt_lr=False, length=20, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, mask_first_epoch=False, milestones=[10], min_lr=1e-05, model='vit_base_patch16_224', model_num=0, momentum=0.9, n_centroids=10, nb_classes=200, no_auto=1, not_train_ca=False, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, original_model='vit_base_patch16_224', original_model_mlp_structure=[2], output_dir='./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362', patience_epochs=10, pin_mem=True, predefined_key='', pretrained=True, print_freq=10, prompt_key=False, prompt_key_init='uniform', prompt_momentum=0.01, prompt_pool=True, pull_constraint=True, pull_constraint_coeff=1.0, recount=1, reg=0.01, reinit_optimizer=True, remode='pixel', reprob=0.0, same_key_value=False, sched='step', seed=42, shared_prompt_key=False, shared_prompt_pool=True, shuffle=False, size=10, smoothing=0.1, subparser_name='cub_hideprompt_5e', task_inc=False, threshold=0.95, threshold2=0.1, threshold_pretrained=0.95, top_k=1, topk_old_subspace=1, train_inference_task_only=False, train_interpolation='bicubic', train_mask=True, trained_original_model='./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt', unscale_lr=True, use_e_prompt=True, use_g_prompt=False, use_old_subspace_forward=0, use_pre_gradient_constraint=1, use_prefix_tune_for_e_prompt=True, use_prefix_tune_for_g_prompt=False, use_prompt_mask=True, warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 1689800
Start training for 50 epochs
args.config:  cub_hideprompt_5e
>>> pretrained data exists
dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
layer 0 item key r 251
----------------------------------------
Gradient Constraints Summary (768, 251)
----------------------------------------
layer 1 item key r 158
----------------------------------------
Gradient Constraints Summary (768, 158)
----------------------------------------
layer 2 item key r 161
----------------------------------------
Gradient Constraints Summary (768, 161)
----------------------------------------
layer 3 item key r 87
----------------------------------------
Gradient Constraints Summary (768, 87)
----------------------------------------
layer 4 item key r 46
----------------------------------------
Gradient Constraints Summary (768, 46)
----------------------------------------
layer 5 item key r 59
----------------------------------------
Gradient Constraints Summary (768, 59)
----------------------------------------
layer 6 item key r 60
----------------------------------------
Gradient Constraints Summary (768, 60)
----------------------------------------
layer 7 item key r 60
----------------------------------------
Gradient Constraints Summary (768, 60)
----------------------------------------
layer 8 item key r 60
----------------------------------------
Gradient Constraints Summary (768, 60)
----------------------------------------
layer 9 item key r 60
----------------------------------------
Gradient Constraints Summary (768, 60)
----------------------------------------
layer 10 item key r 61
----------------------------------------
Gradient Constraints Summary (768, 61)
----------------------------------------
layer 11 item key r 73
----------------------------------------
Gradient Constraints Summary (768, 73)
----------------------------------------
dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
e 0 key torch.Size([768, 768])
item key
e 1 key torch.Size([768, 768])
item key
e 2 key torch.Size([768, 768])
item key
e 3 key torch.Size([768, 768])
item key
e 4 key torch.Size([768, 768])
item key
e 5 key torch.Size([768, 768])
item key
e 6 key torch.Size([768, 768])
item key
e 7 key torch.Size([768, 768])
item key
e 8 key torch.Size([768, 768])
item key
e 9 key torch.Size([768, 768])
item key
e 10 key torch.Size([768, 768])
item key
e 11 key torch.Size([768, 768])
item key
>>> processing on task: 0
----------------def modify_available_list----------------
>>> before modify: {}
>>> : task0
>>> after modify: {0: 0}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task1_checkpoint.pth
>>> : task0, no need to re-init params
* Acc@task 100.000 Acc@1 94.369 Acc@5 100.000 loss 0.248
[Average accuracy till task1]	Acc@task: 100.0000	Acc@1: 94.3689	Acc@5: 100.0000	Loss: 0.2480
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
>>> processing on task: 1
----------------def modify_available_list----------------
>>> before modify: {0: 0}
>>> : task1
>>> after modify: {0: 0, 1: 1}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task2_checkpoint.pth
>>> : task1, no need to re-init params
torch.Size([5, 2, 20, 12, 64])
torch.Size([5, 2, 1, 20, 12, 64])
* Acc@task 93.592 Acc@1 91.845 Acc@5 99.612 loss 0.310
* Acc@task 97.913 Acc@1 85.739 Acc@5 99.478 loss 0.481
[Average accuracy till task2]	Acc@task: 95.7526	Acc@1: 88.7919	Acc@5: 99.5450	Loss: 0.3956	Forgetting: 2.5243	Backward: -2.5243
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
>>> processing on task: 2
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1}
>>> : task2
>>> after modify: {0: 0, 1: 1, 2: 2}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task3_checkpoint.pth
>>> : task2, no need to re-init params
torch.Size([5, 2, 20, 12, 64])
torch.Size([5, 2, 1, 20, 12, 64])
* Acc@task 88.350 Acc@1 89.515 Acc@5 99.223 loss 0.376
* Acc@task 92.348 Acc@1 82.783 Acc@5 98.783 loss 0.557
* Acc@task 92.450 Acc@1 91.107 Acc@5 98.658 loss 0.338
[Average accuracy till task3]	Acc@task: 91.0490	Acc@1: 87.8015	Acc@5: 98.8879	Loss: 0.4237	Forgetting: 3.9054	Backward: -3.9054
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
>>> processing on task: 3
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2}
>>> : task3
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task4_checkpoint.pth
>>> : task3, no need to re-init params
torch.Size([5, 2, 20, 12, 64])
torch.Size([5, 2, 1, 20, 12, 64])
* Acc@task 88.932 Acc@1 89.515 Acc@5 98.835 loss 0.372
* Acc@task 89.391 Acc@1 82.261 Acc@5 98.783 loss 0.571
* Acc@task 85.906 Acc@1 85.235 Acc@5 98.490 loss 0.496
* Acc@task 91.809 Acc@1 84.471 Acc@5 98.805 loss 0.514
[Average accuracy till task4]	Acc@task: 89.0096	Acc@1: 85.3703	Acc@5: 98.7282	Loss: 0.4883	Forgetting: 4.7350	Backward: -4.7350
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
>>> processing on task: 4
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3}
>>> : task4
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task5_checkpoint.pth
>>> : task4, no need to re-init params
torch.Size([5, 2, 20, 12, 64])
torch.Size([5, 2, 1, 20, 12, 64])
* Acc@task 88.932 Acc@1 88.738 Acc@5 98.447 loss 0.386
* Acc@task 89.739 Acc@1 81.217 Acc@5 98.957 loss 0.597
* Acc@task 86.577 Acc@1 85.738 Acc@5 98.322 loss 0.513
* Acc@task 87.201 Acc@1 82.935 Acc@5 98.294 loss 0.584
* Acc@task 94.764 Acc@1 93.074 Acc@5 99.155 loss 0.261
[Average accuracy till task5]	Acc@task: 89.4426	Acc@1: 86.3406	Acc@5: 98.6348	Loss: 0.4682	Forgetting: 4.2644	Backward: -4.2644
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
>>> processing on task: 5
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}
>>> : task5
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task6_checkpoint.pth
>>> : task5, no need to re-init params
torch.Size([5, 2, 20, 12, 64])
torch.Size([5, 2, 1, 20, 12, 64])
* Acc@task 89.515 Acc@1 89.126 Acc@5 98.252 loss 0.394
* Acc@task 82.087 Acc@1 77.043 Acc@5 98.435 loss 0.701
* Acc@task 84.732 Acc@1 85.067 Acc@5 98.154 loss 0.527
* Acc@task 88.055 Acc@1 82.765 Acc@5 98.294 loss 0.577
* Acc@task 90.372 Acc@1 93.243 Acc@5 98.818 loss 0.280
* Acc@task 91.343 Acc@1 86.396 Acc@5 98.057 loss 0.520
[Average accuracy till task6]	Acc@task: 87.6837	Acc@1: 85.6067	Acc@5: 98.3349	Loss: 0.4997	Forgetting: 4.3370	Backward: -4.3032
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
>>> processing on task: 6
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}
>>> : task6
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task7_checkpoint.pth
>>> : task6, no need to re-init params
torch.Size([5, 2, 20, 12, 64])
torch.Size([5, 2, 1, 20, 12, 64])
* Acc@task 90.097 Acc@1 88.350 Acc@5 97.670 loss 0.405
* Acc@task 80.522 Acc@1 75.652 Acc@5 98.435 loss 0.718
* Acc@task 84.060 Acc@1 85.403 Acc@5 97.987 loss 0.528
* Acc@task 87.031 Acc@1 82.423 Acc@5 98.123 loss 0.592
* Acc@task 88.682 Acc@1 92.399 Acc@5 98.649 loss 0.282
* Acc@task 88.693 Acc@1 85.159 Acc@5 97.703 loss 0.574
* Acc@task 91.137 Acc@1 86.957 Acc@5 96.823 loss 0.617
[Average accuracy till task7]	Acc@task: 87.1746	Acc@1: 85.1917	Acc@5: 97.9127	Loss: 0.5310	Forgetting: 4.3234	Backward: -4.2952
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
>>> processing on task: 7
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}
>>> : task7
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task8_checkpoint.pth
>>> : task7, no need to re-init params
torch.Size([5, 2, 20, 12, 64])
torch.Size([5, 2, 1, 20, 12, 64])
* Acc@task 90.485 Acc@1 88.544 Acc@5 97.670 loss 0.427
* Acc@task 81.043 Acc@1 75.478 Acc@5 98.087 loss 0.724
* Acc@task 86.409 Acc@1 86.577 Acc@5 97.483 loss 0.523
* Acc@task 86.689 Acc@1 82.253 Acc@5 98.294 loss 0.599
* Acc@task 89.527 Acc@1 92.905 Acc@5 98.649 loss 0.289
* Acc@task 87.279 Acc@1 85.336 Acc@5 97.173 loss 0.571
* Acc@task 90.803 Acc@1 86.957 Acc@5 96.990 loss 0.586
* Acc@task 95.051 Acc@1 82.935 Acc@5 97.440 loss 0.652
[Average accuracy till task8]	Acc@task: 88.4110	Acc@1: 85.1231	Acc@5: 97.7232	Loss: 0.5464	Forgetting: 3.4618	Backward: -3.4377
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
>>> processing on task: 8
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}
>>> : task8
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task9_checkpoint.pth
>>> : task8, no need to re-init params
torch.Size([5, 2, 20, 12, 64])
torch.Size([5, 2, 1, 20, 12, 64])
* Acc@task 88.738 Acc@1 88.155 Acc@5 97.476 loss 0.427
* Acc@task 80.174 Acc@1 74.957 Acc@5 97.913 loss 0.741
* Acc@task 84.899 Acc@1 85.738 Acc@5 97.819 loss 0.547
* Acc@task 87.884 Acc@1 82.594 Acc@5 98.294 loss 0.591
* Acc@task 90.372 Acc@1 93.243 Acc@5 98.480 loss 0.300
* Acc@task 86.219 Acc@1 85.336 Acc@5 96.996 loss 0.588
* Acc@task 89.465 Acc@1 86.288 Acc@5 96.823 loss 0.586
* Acc@task 91.468 Acc@1 83.106 Acc@5 97.099 loss 0.671
* Acc@task 90.372 Acc@1 85.473 Acc@5 93.919 loss 0.763
[Average accuracy till task9]	Acc@task: 87.7322	Acc@1: 84.9877	Acc@5: 97.2020	Loss: 0.5793	Forgetting: 3.2464	Backward: -3.2040
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
>>> processing on task: 9
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8}
>>> : task9
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}
----------------def modify_available_list----------------
Loading checkpoint from: ./ckpt_for_hidep/cub/cub_b_0_inc_20/cub_hideprompt_5e/stage_one_ckpt/checkpoint/task10_checkpoint.pth
>>> : task9, no need to re-init params
torch.Size([5, 2, 20, 12, 64])
torch.Size([5, 2, 1, 20, 12, 64])
* Acc@task 89.320 Acc@1 87.961 Acc@5 97.476 loss 0.428
* Acc@task 80.870 Acc@1 75.130 Acc@5 98.087 loss 0.738
* Acc@task 83.893 Acc@1 84.899 Acc@5 97.148 loss 0.569
* Acc@task 87.201 Acc@1 83.106 Acc@5 98.464 loss 0.590
* Acc@task 89.696 Acc@1 93.074 Acc@5 98.480 loss 0.303
* Acc@task 87.809 Acc@1 85.336 Acc@5 96.820 loss 0.574
* Acc@task 89.799 Acc@1 86.120 Acc@5 96.823 loss 0.582
* Acc@task 90.444 Acc@1 82.253 Acc@5 97.440 loss 0.663
* Acc@task 88.682 Acc@1 83.953 Acc@5 93.581 loss 0.810
* Acc@task 98.129 Acc@1 94.048 Acc@5 98.299 loss 0.345
[Average accuracy till task10]	Acc@task: 88.5844	Acc@1: 85.5880	Acc@5: 97.2617	Loss: 0.5602	Forgetting: 3.2254	Backward: -3.1876
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/hideprompt/baseline/cub_hideprompt_5e/test_56362/array_log.txt
Total training time: 0:38:05
