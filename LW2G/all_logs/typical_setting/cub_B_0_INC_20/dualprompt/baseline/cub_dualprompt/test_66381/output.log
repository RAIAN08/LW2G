200
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79], [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119], [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139], [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159], [160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]]
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, angle_epsilon=0.18, batch_size=24, batchwise_prompt=False, clip_grad=1.0, color_jitter=None, config='cub_dualprompt', cooldown_epochs=10, data_path='./datasets/', dataset='Split-CUB200', dataset_name='cub', decay_epochs=30, decay_rate=0.1, device='cuda', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, e_prompt_layer_idx=[2, 3, 4], embedding_key='cls', epochs=50, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], g_prompt_layer_idx=[0, 1], g_prompt_length=5, global_pool='token', head_type='token', initializer='uniform', input_size=224, length=20, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, mask_first_epoch=False, min_lr=1e-05, model='vit_base_patch16_224', model_num=0, momentum=0.9, nb_classes=200, no_auto=1, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, original_model='vit_base_patch16_224', output_dir='./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381', patience_epochs=10, pin_mem=True, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=1.0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, same_key_value=False, sched='step', seed=42, separated_head=False, shared_prompt_key=False, shared_prompt_pool=True, shuffle=False, size=10, smoothing=0.1, subparser_name='cub_dualprompt', task_inc=False, threshold=0.95, threshold2=0.1, threshold_pretrained=0.95, top_k=1, topk_old_subspace=1, train_interpolation='bicubic', train_mask=True, unscale_lr=True, use_e_prompt=True, use_g_prompt=True, use_old_subspace_forward=0, use_pre_gradient_constraint=1, use_prefix_tune_for_e_prompt=True, use_prefix_tune_for_g_prompt=True, use_prompt_mask=True, warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 1098440
Start training for 50 epochs
args.config:  cub_dualprompt
>>> pretrained data exists
dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
layer 0 item key r 243
----------------------------------------
Gradient Constraints Summary (768, 243)
----------------------------------------
layer 1 item key r 143
----------------------------------------
Gradient Constraints Summary (768, 143)
----------------------------------------
layer 2 item key r 144
----------------------------------------
Gradient Constraints Summary (768, 144)
----------------------------------------
layer 3 item key r 79
----------------------------------------
Gradient Constraints Summary (768, 79)
----------------------------------------
layer 4 item key r 45
----------------------------------------
Gradient Constraints Summary (768, 45)
----------------------------------------
layer 5 item key r 58
----------------------------------------
Gradient Constraints Summary (768, 58)
----------------------------------------
layer 6 item key r 59
----------------------------------------
Gradient Constraints Summary (768, 59)
----------------------------------------
layer 7 item key r 59
----------------------------------------
Gradient Constraints Summary (768, 59)
----------------------------------------
layer 8 item key r 59
----------------------------------------
Gradient Constraints Summary (768, 59)
----------------------------------------
layer 9 item key r 59
----------------------------------------
Gradient Constraints Summary (768, 59)
----------------------------------------
layer 10 item key r 60
----------------------------------------
Gradient Constraints Summary (768, 60)
----------------------------------------
layer 11 item key r 71
----------------------------------------
Gradient Constraints Summary (768, 71)
----------------------------------------
dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
e 0 key torch.Size([768, 768])
item key
e 1 key torch.Size([768, 768])
item key
e 2 key torch.Size([768, 768])
item key
e 3 key torch.Size([768, 768])
item key
e 4 key torch.Size([768, 768])
item key
e 5 key torch.Size([768, 768])
item key
e 6 key torch.Size([768, 768])
item key
e 7 key torch.Size([768, 768])
item key
e 8 key torch.Size([768, 768])
item key
e 9 key torch.Size([768, 768])
item key
e 10 key torch.Size([768, 768])
item key
e 11 key torch.Size([768, 768])
item key
>>> processing on task: 0
----------------def modify_available_list----------------
>>> before modify: {}
>>> : task0
>>> after modify: {0: 0}
----------------def modify_available_list----------------
>>> : task0, no need to re-init params
>>> : task0, no need to re-init keys
* Acc@task 100.000 Acc@1 94.563 Acc@5 100.000 loss 0.248
[Average accuracy till task1]	Acc@task: 100.0000	Acc@1: 94.5631	Acc@5: 100.0000	Loss: 0.2476
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
>>> processing on task: 1
----------------def modify_available_list----------------
>>> before modify: {0: 0}
>>> : task1
>>> after modify: {0: 0, 1: 1}
----------------def modify_available_list----------------
>>> : task1, no need to re-init params
>>> : task1, no need to re-init keys
* Acc@task 84.272 Acc@1 91.068 Acc@5 99.612 loss 0.326
* Acc@task 93.739 Acc@1 83.304 Acc@5 99.304 loss 0.509
[Average accuracy till task2]	Acc@task: 89.0055	Acc@1: 87.1862	Acc@5: 99.4580	Loss: 0.4173	Forgetting: 3.4951	Backward: -3.4951
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
>>> processing on task: 2
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1}
>>> : task2
>>> after modify: {0: 0, 1: 1, 2: 2}
----------------def modify_available_list----------------
>>> : task2, no need to re-init params
>>> : task2, no need to re-init keys
* Acc@task 77.282 Acc@1 86.602 Acc@5 99.029 loss 0.490
* Acc@task 88.000 Acc@1 73.391 Acc@5 98.435 loss 0.783
* Acc@task 80.537 Acc@1 93.792 Acc@5 99.161 loss 0.235
[Average accuracy till task3]	Acc@task: 81.9395	Acc@1: 84.5951	Acc@5: 98.8750	Loss: 0.5026	Forgetting: 8.9371	Backward: -8.9371
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
>>> processing on task: 3
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2}
>>> : task3
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3}
----------------def modify_available_list----------------
>>> : task3, no need to re-init params
>>> : task3, no need to re-init keys
* Acc@task 75.340 Acc@1 86.214 Acc@5 98.835 loss 0.506
* Acc@task 87.826 Acc@1 73.913 Acc@5 98.087 loss 0.793
* Acc@task 66.107 Acc@1 91.443 Acc@5 98.993 loss 0.319
* Acc@task 83.447 Acc@1 81.570 Acc@5 98.464 loss 0.597
[Average accuracy till task4]	Acc@task: 78.1801	Acc@1: 83.2849	Acc@5: 98.5948	Loss: 0.5535	Forgetting: 6.6966	Backward: -6.6966
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
>>> processing on task: 4
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3}
>>> : task4
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}
----------------def modify_available_list----------------
>>> : task4, no need to re-init params
>>> : task4, no need to re-init keys
* Acc@task 75.146 Acc@1 85.825 Acc@5 98.835 loss 0.503
* Acc@task 84.870 Acc@1 72.696 Acc@5 98.087 loss 0.822
* Acc@task 65.268 Acc@1 89.933 Acc@5 98.322 loss 0.360
* Acc@task 73.549 Acc@1 76.621 Acc@5 97.782 loss 0.707
* Acc@task 80.743 Acc@1 95.608 Acc@5 98.649 loss 0.213
[Average accuracy till task5]	Acc@task: 75.9153	Acc@1: 84.1366	Acc@5: 98.3349	Loss: 0.5210	Forgetting: 7.0386	Backward: -7.0386
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
>>> processing on task: 5
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}
>>> : task5
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}
----------------def modify_available_list----------------
>>> : task5, no need to re-init params
>>> : task5, no need to re-init keys
* Acc@task 73.592 Acc@1 86.019 Acc@5 98.447 loss 0.518
* Acc@task 73.391 Acc@1 64.348 Acc@5 97.565 loss 1.006
* Acc@task 64.094 Acc@1 89.094 Acc@5 98.490 loss 0.385
* Acc@task 71.502 Acc@1 76.621 Acc@5 97.952 loss 0.729
* Acc@task 73.311 Acc@1 92.905 Acc@5 98.818 loss 0.289
* Acc@task 64.664 Acc@1 88.869 Acc@5 97.880 loss 0.530
[Average accuracy till task6]	Acc@task: 70.0924	Acc@1: 82.9762	Acc@5: 98.1919	Loss: 0.5761	Forgetting: 7.9699	Backward: -7.9699
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
>>> processing on task: 6
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}
>>> : task6
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}
----------------def modify_available_list----------------
>>> : task6, no need to re-init params
>>> : task6, no need to re-init keys
* Acc@task 69.126 Acc@1 86.019 Acc@5 97.864 loss 0.520
* Acc@task 73.391 Acc@1 63.478 Acc@5 96.696 loss 1.065
* Acc@task 63.423 Acc@1 89.262 Acc@5 98.322 loss 0.392
* Acc@task 71.502 Acc@1 76.280 Acc@5 97.782 loss 0.759
* Acc@task 73.142 Acc@1 92.230 Acc@5 98.818 loss 0.300
* Acc@task 37.456 Acc@1 87.633 Acc@5 97.527 loss 0.558
* Acc@task 74.916 Acc@1 82.441 Acc@5 95.151 loss 0.791
[Average accuracy till task7]	Acc@task: 66.1366	Acc@1: 82.4776	Acc@5: 97.4511	Loss: 0.6265	Forgetting: 7.1342	Backward: -7.1342
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
>>> processing on task: 7
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}
>>> : task7
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}
----------------def modify_available_list----------------
>>> : task7, no need to re-init params
>>> : task7, no need to re-init keys
* Acc@task 68.350 Acc@1 84.854 Acc@5 97.864 loss 0.560
* Acc@task 73.217 Acc@1 64.522 Acc@5 96.348 loss 1.074
* Acc@task 63.423 Acc@1 88.591 Acc@5 97.651 loss 0.426
* Acc@task 70.990 Acc@1 76.451 Acc@5 97.270 loss 0.814
* Acc@task 72.466 Acc@1 92.061 Acc@5 98.649 loss 0.333
* Acc@task 36.219 Acc@1 86.749 Acc@5 97.350 loss 0.597
* Acc@task 74.916 Acc@1 79.599 Acc@5 94.983 loss 0.868
* Acc@task 74.061 Acc@1 82.423 Acc@5 95.904 loss 0.757
[Average accuracy till task8]	Acc@task: 66.7053	Acc@1: 81.9061	Acc@5: 97.0023	Loss: 0.6786	Forgetting: 6.7603	Backward: -6.7603
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
>>> processing on task: 8
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}
>>> : task8
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8}
----------------def modify_available_list----------------
>>> : task8, no need to re-init params
>>> : task8, no need to re-init keys
* Acc@task 63.301 Acc@1 84.466 Acc@5 97.282 loss 0.569
* Acc@task 73.217 Acc@1 63.826 Acc@5 95.652 loss 1.092
* Acc@task 62.752 Acc@1 88.758 Acc@5 97.651 loss 0.424
* Acc@task 70.990 Acc@1 76.109 Acc@5 96.928 loss 0.823
* Acc@task 69.595 Acc@1 93.074 Acc@5 98.480 loss 0.325
* Acc@task 34.276 Acc@1 86.572 Acc@5 96.466 loss 0.614
* Acc@task 74.749 Acc@1 78.261 Acc@5 94.147 loss 0.912
* Acc@task 56.485 Acc@1 80.375 Acc@5 95.904 loss 0.781
* Acc@task 95.608 Acc@1 83.277 Acc@5 93.412 loss 0.953
[Average accuracy till task9]	Acc@task: 66.7747	Acc@1: 81.6355	Acc@5: 96.2137	Loss: 0.7215	Forgetting: 6.3911	Backward: -6.3911
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
>>> processing on task: 9
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8}
>>> : task9
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}
----------------def modify_available_list----------------
>>> : task9, no need to re-init params
>>> : task9, no need to re-init keys
* Acc@task 63.301 Acc@1 84.078 Acc@5 97.670 loss 0.588
* Acc@task 65.043 Acc@1 65.217 Acc@5 95.304 loss 1.079
* Acc@task 62.584 Acc@1 89.094 Acc@5 97.483 loss 0.435
* Acc@task 70.990 Acc@1 73.038 Acc@5 97.099 loss 0.879
* Acc@task 69.257 Acc@1 92.568 Acc@5 98.480 loss 0.341
* Acc@task 33.922 Acc@1 85.866 Acc@5 96.466 loss 0.631
* Acc@task 74.749 Acc@1 78.595 Acc@5 94.147 loss 0.939
* Acc@task 56.485 Acc@1 81.399 Acc@5 95.222 loss 0.812
* Acc@task 95.608 Acc@1 78.378 Acc@5 92.061 loss 1.111
* Acc@task 75.170 Acc@1 92.687 Acc@5 97.789 loss 0.420
[Average accuracy till task10]	Acc@task: 66.7109	Acc@1: 82.0920	Acc@5: 96.1722	Loss: 0.7234	Forgetting: 6.4017	Backward: -6.4017
NumPy array :stat_matrix saved to ./typical_setting/cub_B_0_INC_20/dualprompt/baseline/cub_dualprompt/test_66381/array_log.txt
Total training time: 1:11:20
