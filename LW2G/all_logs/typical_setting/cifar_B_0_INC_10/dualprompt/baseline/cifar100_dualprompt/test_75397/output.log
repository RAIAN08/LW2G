Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
100
[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], [20, 21, 22, 23, 24, 25, 26, 27, 28, 29], [30, 31, 32, 33, 34, 35, 36, 37, 38, 39], [40, 41, 42, 43, 44, 45, 46, 47, 48, 49], [50, 51, 52, 53, 54, 55, 56, 57, 58, 59], [60, 61, 62, 63, 64, 65, 66, 67, 68, 69], [70, 71, 72, 73, 74, 75, 76, 77, 78, 79], [80, 81, 82, 83, 84, 85, 86, 87, 88, 89], [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, angle_epsilon=0.18, batch_size=24, batchwise_prompt=False, clip_grad=1.0, color_jitter=None, config='cifar100_dualprompt', cooldown_epochs=10, data_path='./datasets/', dataset='Split-CIFAR100', dataset_name='cifar100', decay_epochs=30, decay_rate=0.1, device='cuda', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, e_prompt_layer_idx=[2, 3, 4], embedding_key='cls', epochs=40, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], g_prompt_layer_idx=[0, 1], g_prompt_length=5, global_pool='token', head_type='token', initializer='uniform', input_size=224, length=20, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, mask_first_epoch=False, min_lr=1e-05, model='vit_base_patch16_224', model_num=0, momentum=0.9, nb_classes=100, no_auto=1, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, original_model='vit_base_patch16_224', output_dir='./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397', patience_epochs=10, pin_mem=True, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=1.0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, same_key_value=False, sched='constant', seed=42, separated_head=False, shared_prompt_key=False, shared_prompt_pool=True, shuffle=False, size=10, smoothing=0.1, subparser_name='cifar100_dualprompt', task_inc=False, threshold=0.95, threshold2=0.1, threshold_pretrained=0.95, top_k=1, topk_old_subspace=1, train_interpolation='bicubic', train_mask=True, unscale_lr=True, use_e_prompt=True, use_g_prompt=True, use_old_subspace_forward=0, use_pre_gradient_constraint=1, use_prefix_tune_for_e_prompt=True, use_prefix_tune_for_g_prompt=True, use_prompt_mask=True, warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.0, world_size=8)
number of params: 1021540
Start training for 40 epochs
args.config:  cifar100_dualprompt
>>> pretrained data exists
dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
layer 0 item key r 27
----------------------------------------
Gradient Constraints Summary (768, 27)
----------------------------------------
layer 1 item key r 84
----------------------------------------
Gradient Constraints Summary (768, 84)
----------------------------------------
layer 2 item key r 151
----------------------------------------
Gradient Constraints Summary (768, 151)
----------------------------------------
layer 3 item key r 259
----------------------------------------
Gradient Constraints Summary (768, 259)
----------------------------------------
layer 4 item key r 78
----------------------------------------
Gradient Constraints Summary (768, 78)
----------------------------------------
layer 5 item key r 72
----------------------------------------
Gradient Constraints Summary (768, 72)
----------------------------------------
layer 6 item key r 71
----------------------------------------
Gradient Constraints Summary (768, 71)
----------------------------------------
layer 7 item key r 71
----------------------------------------
Gradient Constraints Summary (768, 71)
----------------------------------------
layer 8 item key r 71
----------------------------------------
Gradient Constraints Summary (768, 71)
----------------------------------------
layer 9 item key r 71
----------------------------------------
Gradient Constraints Summary (768, 71)
----------------------------------------
layer 10 item key r 73
----------------------------------------
Gradient Constraints Summary (768, 73)
----------------------------------------
layer 11 item key r 79
----------------------------------------
Gradient Constraints Summary (768, 79)
----------------------------------------
dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])
e 0 key torch.Size([768, 768])
item key
e 1 key torch.Size([768, 768])
item key
e 2 key torch.Size([768, 768])
item key
e 3 key torch.Size([768, 768])
item key
e 4 key torch.Size([768, 768])
item key
e 5 key torch.Size([768, 768])
item key
e 6 key torch.Size([768, 768])
item key
e 7 key torch.Size([768, 768])
item key
e 8 key torch.Size([768, 768])
item key
e 9 key torch.Size([768, 768])
item key
e 10 key torch.Size([768, 768])
item key
e 11 key torch.Size([768, 768])
item key
>>> processing on task: 0
----------------def modify_available_list----------------
>>> before modify: {}
>>> : task0
>>> after modify: {0: 0}
----------------def modify_available_list----------------
>>> : task0, no need to re-init params
>>> : task0, no need to re-init keys
* Acc@task 100.000 Acc@1 99.400 Acc@5 100.000 loss 0.046
[Average accuracy till task1]	Acc@task: 100.0000	Acc@1: 99.4000	Acc@5: 100.0000	Loss: 0.0458
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
>>> processing on task: 1
----------------def modify_available_list----------------
>>> before modify: {0: 0}
>>> : task1
>>> after modify: {0: 0, 1: 1}
----------------def modify_available_list----------------
>>> : task1, no need to re-init params
>>> : task1, no need to re-init keys
* Acc@task 91.400 Acc@1 97.400 Acc@5 100.000 loss 0.102
* Acc@task 84.400 Acc@1 96.100 Acc@5 99.800 loss 0.184
[Average accuracy till task2]	Acc@task: 87.9000	Acc@1: 96.7500	Acc@5: 99.9000	Loss: 0.1427	Forgetting: 2.0000	Backward: -2.0000
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
>>> processing on task: 2
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1}
>>> : task2
>>> after modify: {0: 0, 1: 1, 2: 2}
----------------def modify_available_list----------------
>>> : task2, no need to re-init params
>>> : task2, no need to re-init keys
* Acc@task 83.500 Acc@1 95.600 Acc@5 100.000 loss 0.142
* Acc@task 76.900 Acc@1 94.100 Acc@5 99.500 loss 0.244
* Acc@task 85.000 Acc@1 93.900 Acc@5 99.300 loss 0.257
[Average accuracy till task3]	Acc@task: 81.8000	Acc@1: 94.5333	Acc@5: 99.6000	Loss: 0.2145	Forgetting: 2.9000	Backward: -2.9000
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
>>> processing on task: 3
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2}
>>> : task3
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3}
----------------def modify_available_list----------------
>>> : task3, no need to re-init params
>>> : task3, no need to re-init keys
* Acc@task 76.800 Acc@1 94.500 Acc@5 99.900 loss 0.175
* Acc@task 71.900 Acc@1 91.900 Acc@5 99.200 loss 0.296
* Acc@task 80.200 Acc@1 92.500 Acc@5 99.000 loss 0.297
* Acc@task 69.900 Acc@1 91.000 Acc@5 99.200 loss 0.278
[Average accuracy till task4]	Acc@task: 74.7000	Acc@1: 92.4750	Acc@5: 99.3250	Loss: 0.2613	Forgetting: 3.5000	Backward: -3.5000
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
>>> processing on task: 4
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3}
>>> : task4
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}
----------------def modify_available_list----------------
>>> : task4, no need to re-init params
>>> : task4, no need to re-init keys
* Acc@task 74.900 Acc@1 93.700 Acc@5 99.900 loss 0.204
* Acc@task 70.000 Acc@1 89.700 Acc@5 99.000 loss 0.355
* Acc@task 76.300 Acc@1 90.100 Acc@5 98.700 loss 0.361
* Acc@task 66.400 Acc@1 89.400 Acc@5 98.900 loss 0.324
* Acc@task 64.400 Acc@1 92.500 Acc@5 99.200 loss 0.275
[Average accuracy till task5]	Acc@task: 70.4000	Acc@1: 91.0800	Acc@5: 99.1400	Loss: 0.3038	Forgetting: 4.3750	Backward: -4.3750
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
>>> processing on task: 5
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4}
>>> : task5
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}
----------------def modify_available_list----------------
>>> : task5, no need to re-init params
>>> : task5, no need to re-init keys
* Acc@task 73.600 Acc@1 91.700 Acc@5 99.900 loss 0.251
* Acc@task 66.700 Acc@1 88.800 Acc@5 99.000 loss 0.393
* Acc@task 76.200 Acc@1 89.500 Acc@5 98.500 loss 0.384
* Acc@task 63.000 Acc@1 87.900 Acc@5 98.400 loss 0.388
* Acc@task 56.600 Acc@1 92.000 Acc@5 99.000 loss 0.302
* Acc@task 68.900 Acc@1 82.700 Acc@5 99.200 loss 0.586
[Average accuracy till task6]	Acc@task: 67.5000	Acc@1: 88.7667	Acc@5: 99.0000	Loss: 0.3840	Forgetting: 4.6000	Backward: -4.6000
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
>>> processing on task: 6
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}
>>> : task6
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}
----------------def modify_available_list----------------
>>> : task6, no need to re-init params
>>> : task6, no need to re-init keys
* Acc@task 71.700 Acc@1 92.300 Acc@5 99.400 loss 0.254
* Acc@task 66.000 Acc@1 86.700 Acc@5 99.000 loss 0.440
* Acc@task 72.400 Acc@1 90.200 Acc@5 98.300 loss 0.404
* Acc@task 61.300 Acc@1 87.600 Acc@5 98.500 loss 0.417
* Acc@task 55.500 Acc@1 91.500 Acc@5 98.900 loss 0.313
* Acc@task 68.000 Acc@1 82.200 Acc@5 98.800 loss 0.625
* Acc@task 60.500 Acc@1 89.300 Acc@5 98.000 loss 0.368
[Average accuracy till task7]	Acc@task: 65.0571	Acc@1: 88.5429	Acc@5: 98.7000	Loss: 0.4030	Forgetting: 4.1833	Backward: -4.1833
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
>>> processing on task: 7
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}
>>> : task7
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}
----------------def modify_available_list----------------
>>> : task7, no need to re-init params
>>> : task7, no need to re-init keys
* Acc@task 71.000 Acc@1 91.800 Acc@5 99.200 loss 0.276
* Acc@task 65.200 Acc@1 87.000 Acc@5 98.900 loss 0.448
* Acc@task 68.400 Acc@1 88.100 Acc@5 98.300 loss 0.429
* Acc@task 58.300 Acc@1 87.100 Acc@5 98.200 loss 0.449
* Acc@task 53.300 Acc@1 90.700 Acc@5 98.700 loss 0.337
* Acc@task 67.400 Acc@1 81.200 Acc@5 98.900 loss 0.644
* Acc@task 53.500 Acc@1 87.200 Acc@5 97.600 loss 0.441
* Acc@task 60.100 Acc@1 90.700 Acc@5 98.300 loss 0.348
[Average accuracy till task8]	Acc@task: 62.1500	Acc@1: 87.9750	Acc@5: 98.5125	Loss: 0.4216	Forgetting: 4.5429	Backward: -4.5429
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
>>> processing on task: 8
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}
>>> : task8
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8}
----------------def modify_available_list----------------
>>> : task8, no need to re-init params
>>> : task8, no need to re-init keys
* Acc@task 68.100 Acc@1 90.800 Acc@5 98.800 loss 0.312
* Acc@task 59.300 Acc@1 85.700 Acc@5 98.400 loss 0.490
* Acc@task 66.500 Acc@1 88.000 Acc@5 98.100 loss 0.440
* Acc@task 58.000 Acc@1 86.500 Acc@5 98.100 loss 0.436
* Acc@task 51.100 Acc@1 90.000 Acc@5 98.600 loss 0.387
* Acc@task 66.700 Acc@1 80.900 Acc@5 98.700 loss 0.627
* Acc@task 53.300 Acc@1 86.800 Acc@5 96.900 loss 0.482
* Acc@task 59.800 Acc@1 89.000 Acc@5 97.400 loss 0.391
* Acc@task 74.200 Acc@1 92.600 Acc@5 99.400 loss 0.235
[Average accuracy till task9]	Acc@task: 61.8889	Acc@1: 87.8111	Acc@5: 98.2667	Loss: 0.4222	Forgetting: 4.7375	Backward: -4.7375
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
>>> processing on task: 9
----------------def modify_available_list----------------
>>> before modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8}
>>> : task9
>>> after modify: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}
----------------def modify_available_list----------------
>>> : task9, no need to re-init params
>>> : task9, no need to re-init keys
* Acc@task 67.800 Acc@1 90.100 Acc@5 98.700 loss 0.346
* Acc@task 58.900 Acc@1 84.700 Acc@5 98.300 loss 0.521
* Acc@task 66.200 Acc@1 87.300 Acc@5 97.900 loss 0.465
* Acc@task 56.900 Acc@1 83.300 Acc@5 97.400 loss 0.536
* Acc@task 50.300 Acc@1 87.600 Acc@5 98.300 loss 0.427
* Acc@task 66.600 Acc@1 79.500 Acc@5 98.400 loss 0.707
* Acc@task 53.000 Acc@1 85.700 Acc@5 96.700 loss 0.540
* Acc@task 57.800 Acc@1 84.700 Acc@5 97.600 loss 0.513
* Acc@task 74.200 Acc@1 87.900 Acc@5 99.100 loss 0.373
* Acc@task 42.700 Acc@1 88.600 Acc@5 99.200 loss 0.335
[Average accuracy till task10]	Acc@task: 59.4400	Acc@1: 85.9400	Acc@5: 98.1600	Loss: 0.4765	Forgetting: 6.3778	Backward: -6.3778
NumPy array :stat_matrix saved to ./typical_setting/cifar_B_0_INC_10/dualprompt/baseline/cifar100_dualprompt/test_75397/array_log.txt
Total training time: 4:18:53
